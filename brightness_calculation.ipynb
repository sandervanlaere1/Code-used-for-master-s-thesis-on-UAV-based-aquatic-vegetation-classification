{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af667d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from roboflow import Roboflow\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe7a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0. CONFIGUREER PATHS ===\n",
    "METADATA_FOLDER = r\"C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\Raw_July\\Testing data\\metadata\"\n",
    "TEST_PATCH_DIR = r\"C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\Raw_July\\Testing data\\test\"\n",
    "OUTPUT_METADATA = r\"C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\metadata_with_brightness.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be7aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Thresholds per class (handmatig gekozen) ===\n",
    "brightness_thresholds = {\n",
    "    \"Clear Water\": 31,\n",
    "    \"Common reed\": 70,\n",
    "    \"Duckweed\": 92,\n",
    "    \"Other\": 56,\n",
    "    \"Water-starwort\": 61\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381256b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata gecombineerd: 2640 rijen\n"
     ]
    }
   ],
   "source": [
    "# === 1. COMBINEER METADATA BESTANDEN EN SORTEER OP SEGMENT ===\n",
    "\n",
    "import re  # Import the re module for regular expressions\n",
    "\n",
    "metadata_dfs = []\n",
    "for file in sorted(os.listdir(METADATA_FOLDER)):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(METADATA_FOLDER, file))\n",
    "        if 'light_condition' in df.columns:\n",
    "            df = df.drop(columns=['light_condition'])\n",
    "        metadata_dfs.append(df)\n",
    "\n",
    "combined_metadata = pd.concat(metadata_dfs, ignore_index=True)\n",
    "\n",
    "def extract_segment_number(segment):\n",
    "    match = re.search(r'F(\\d+)', segment)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "combined_metadata['segment_number'] = combined_metadata['segment'].apply(extract_segment_number)\n",
    "combined_metadata = combined_metadata.sort_values(by='segment_number').drop(columns=['segment_number']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Metadata gecombineerd: {len(combined_metadata)} rijen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb56d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata gefilterd op echte patches: 2330 rijen\n"
     ]
    }
   ],
   "source": [
    "# === 2. FILTER METADATA OP EFFECTIEVE TEST PATCHES ===\n",
    "actual_patches = []\n",
    "for class_name in os.listdir(TEST_PATCH_DIR):\n",
    "    class_dir = os.path.join(TEST_PATCH_DIR, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        if img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            actual_patches.append(img_file)\n",
    "\n",
    "actual_patches_cleaned = []\n",
    "for patch in actual_patches:\n",
    "    match = re.match(r\"^(.*)_jpg\\.rf\\..*\\.jpg$\", patch)\n",
    "    if match:\n",
    "        cleaned = match.group(1) + \".jpg\"\n",
    "        actual_patches_cleaned.append(cleaned)\n",
    "    else:\n",
    "        actual_patches_cleaned.append(patch)\n",
    "\n",
    "combined_metadata['patch_filename_lower'] = combined_metadata['patch_filename'].str.lower()\n",
    "actual_patches_cleaned_lower = [p.lower() for p in actual_patches_cleaned]\n",
    "\n",
    "metadata_filtered = combined_metadata[combined_metadata['patch_filename_lower'].isin(actual_patches_cleaned_lower)].drop(columns=['patch_filename_lower'])\n",
    "\n",
    "print(f\"Metadata gefilterd op echte patches: {len(metadata_filtered)} rijen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28fd67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brightness gemeten: 2330 patches\n"
     ]
    }
   ],
   "source": [
    "# === 3. BRIGHTNESS METEN EN LIGHT CONDITION TOEVOEGEN ===\n",
    "brightness_records = []\n",
    "\n",
    "for class_name in os.listdir(TEST_PATCH_DIR):\n",
    "    class_dir = os.path.join(TEST_PATCH_DIR, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        bright = np.array(img).mean()\n",
    "\n",
    "        threshold = brightness_thresholds.get(class_name, 100)\n",
    "        light_cond = \"shadow\" if bright < threshold else \"sun\"\n",
    "\n",
    "        match = re.match(r\"^(.*)_jpg\\.rf\\..*\\.jpg$\", img_file)\n",
    "        cleaned_name = match.group(1) + \".jpg\" if match else img_file\n",
    "\n",
    "        brightness_records.append({\n",
    "            \"patch_filename\": cleaned_name,\n",
    "            \"true_label\": class_name,      # <-- VOEG DIT TOE\n",
    "            \"brightness\": bright,\n",
    "            \"light_condition_new\": light_cond\n",
    "        })\n",
    "\n",
    "df_brightness = pd.DataFrame(brightness_records)\n",
    "\n",
    "print(f\"Brightness gemeten: {len(df_brightness)} patches\")\n",
    "\n",
    "# Merge brightness info in metadata\n",
    "final_metadata = pd.merge(metadata_filtered, df_brightness, on=\"patch_filename\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d85291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata met brightness succesvol opgeslagen als 'C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\metadata_with_brightness.csv'\n"
     ]
    }
   ],
   "source": [
    "# === 4. MERGE METADATA EN OPSLAAN ===\n",
    "final_metadata = pd.merge(metadata_filtered, df_brightness, on=\"patch_filename\", how=\"left\")\n",
    "final_metadata.to_csv(OUTPUT_METADATA, index=False)\n",
    "\n",
    "print(f\"Metadata met brightness succesvol opgeslagen als '{OUTPUT_METADATA}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be888fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Maak controle plots per klasse ===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Groepeer brightness info per klasse\n",
    "classes = df_brightness['true_label'].unique()\n",
    "\n",
    "# Maak een aparte plot per klasse\n",
    "for class_name in classes:\n",
    "    subset = df_brightness[df_brightness['true_label'] == class_name]\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(subset['brightness'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Threshold lijn toevoegen (indien beschikbaar)\n",
    "    if class_name in brightness_thresholds:\n",
    "        plt.axvline(brightness_thresholds[class_name], color='red', linestyle='--', label=f\"Threshold ({brightness_thresholds[class_name]})\")\n",
    "\n",
    "    plt.title(f\"Brightness Distribution - {class_name}\")\n",
    "    plt.xlabel(\"Brightness (Mean Pixel Value)\")\n",
    "    plt.ylabel(\"Aantal patches\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c1452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Missing patches (in CSV, not in test folder): 132\n",
      "  - F16_0172_patch_1.jpg\n",
      "  - F16_0172_patch_10.jpg\n",
      "  - F16_0172_patch_100.jpg\n",
      "  - F16_0172_patch_101.jpg\n",
      "  - F16_0172_patch_102.jpg\n",
      "  - F16_0172_patch_105.jpg\n",
      "  - F16_0172_patch_106.jpg\n",
      "  - F16_0172_patch_107.jpg\n",
      "  - F16_0172_patch_108.jpg\n",
      "  - F16_0172_patch_109.jpg\n",
      "  - F16_0172_patch_11.jpg\n",
      "  - F16_0172_patch_110.jpg\n",
      "  - F16_0172_patch_113.jpg\n",
      "  - F16_0172_patch_114.jpg\n",
      "  - F16_0172_patch_115.jpg\n",
      "  - F16_0172_patch_116.jpg\n",
      "  - F16_0172_patch_117.jpg\n",
      "  - F16_0172_patch_12.jpg\n",
      "  - F16_0172_patch_121.jpg\n",
      "  - F16_0172_patch_122.jpg\n",
      "  - F16_0172_patch_123.jpg\n",
      "  - F16_0172_patch_124.jpg\n",
      "  - F16_0172_patch_125.jpg\n",
      "  - F16_0172_patch_13.jpg\n",
      "  - F16_0172_patch_130.jpg\n",
      "  - F16_0172_patch_131.jpg\n",
      "  - F16_0172_patch_132.jpg\n",
      "  - F16_0172_patch_133.jpg\n",
      "  - F16_0172_patch_139.jpg\n",
      "  - F16_0172_patch_14.jpg\n",
      "  - F16_0172_patch_140.jpg\n",
      "  - F16_0172_patch_141.jpg\n",
      "  - F16_0172_patch_148.jpg\n",
      "  - F16_0172_patch_149.jpg\n",
      "  - F16_0172_patch_156.jpg\n",
      "  - F16_0172_patch_157.jpg\n",
      "  - F16_0172_patch_164.jpg\n",
      "  - F16_0172_patch_165.jpg\n",
      "  - F16_0172_patch_17.jpg\n",
      "  - F16_0172_patch_172.jpg\n",
      "  - F16_0172_patch_173.jpg\n",
      "  - F16_0172_patch_18.jpg\n",
      "  - F16_0172_patch_180.jpg\n",
      "  - F16_0172_patch_181.jpg\n",
      "  - F16_0172_patch_188.jpg\n",
      "  - F16_0172_patch_189.jpg\n",
      "  - F16_0172_patch_19.jpg\n",
      "  - F16_0172_patch_195.jpg\n",
      "  - F16_0172_patch_196.jpg\n",
      "  - F16_0172_patch_2.jpg\n",
      "  - F16_0172_patch_20.jpg\n",
      "  - F16_0172_patch_202.jpg\n",
      "  - F16_0172_patch_203.jpg\n",
      "  - F16_0172_patch_204.jpg\n",
      "  - F16_0172_patch_209.jpg\n",
      "  - F16_0172_patch_21.jpg\n",
      "  - F16_0172_patch_210.jpg\n",
      "  - F16_0172_patch_211.jpg\n",
      "  - F16_0172_patch_212.jpg\n",
      "  - F16_0172_patch_213.jpg\n",
      "  - F16_0172_patch_217.jpg\n",
      "  - F16_0172_patch_218.jpg\n",
      "  - F16_0172_patch_219.jpg\n",
      "  - F16_0172_patch_22.jpg\n",
      "  - F16_0172_patch_220.jpg\n",
      "  - F16_0172_patch_221.jpg\n",
      "  - F16_0172_patch_225.jpg\n",
      "  - F16_0172_patch_226.jpg\n",
      "  - F16_0172_patch_227.jpg\n",
      "  - F16_0172_patch_228.jpg\n",
      "  - F16_0172_patch_23.jpg\n",
      "  - F16_0172_patch_233.jpg\n",
      "  - F16_0172_patch_234.jpg\n",
      "  - F16_0172_patch_235.jpg\n",
      "  - F16_0172_patch_236.jpg\n",
      "  - F16_0172_patch_26.jpg\n",
      "  - F16_0172_patch_27.jpg\n",
      "  - F16_0172_patch_28.jpg\n",
      "  - F16_0172_patch_29.jpg\n",
      "  - F16_0172_patch_3.jpg\n",
      "  - F16_0172_patch_30.jpg\n",
      "  - F16_0172_patch_33.jpg\n",
      "  - F16_0172_patch_34.jpg\n",
      "  - F16_0172_patch_35.jpg\n",
      "  - F16_0172_patch_36.jpg\n",
      "  - F16_0172_patch_37.jpg\n",
      "  - F16_0172_patch_38.jpg\n",
      "  - F16_0172_patch_4.jpg\n",
      "  - F16_0172_patch_41.jpg\n",
      "  - F16_0172_patch_42.jpg\n",
      "  - F16_0172_patch_43.jpg\n",
      "  - F16_0172_patch_44.jpg\n",
      "  - F16_0172_patch_45.jpg\n",
      "  - F16_0172_patch_46.jpg\n",
      "  - F16_0172_patch_49.jpg\n",
      "  - F16_0172_patch_5.jpg\n",
      "  - F16_0172_patch_50.jpg\n",
      "  - F16_0172_patch_51.jpg\n",
      "  - F16_0172_patch_52.jpg\n",
      "  - F16_0172_patch_53.jpg\n",
      "  - F16_0172_patch_54.jpg\n",
      "  - F16_0172_patch_58.jpg\n",
      "  - F16_0172_patch_59.jpg\n",
      "  - F16_0172_patch_6.jpg\n",
      "  - F16_0172_patch_60.jpg\n",
      "  - F16_0172_patch_61.jpg\n",
      "  - F16_0172_patch_62.jpg\n",
      "  - F16_0172_patch_65.jpg\n",
      "  - F16_0172_patch_66.jpg\n",
      "  - F16_0172_patch_67.jpg\n",
      "  - F16_0172_patch_68.jpg\n",
      "  - F16_0172_patch_69.jpg\n",
      "  - F16_0172_patch_70.jpg\n",
      "  - F16_0172_patch_73.jpg\n",
      "  - F16_0172_patch_74.jpg\n",
      "  - F16_0172_patch_75.jpg\n",
      "  - F16_0172_patch_76.jpg\n",
      "  - F16_0172_patch_77.jpg\n",
      "  - F16_0172_patch_81.jpg\n",
      "  - F16_0172_patch_82.jpg\n",
      "  - F16_0172_patch_83.jpg\n",
      "  - F16_0172_patch_84.jpg\n",
      "  - F16_0172_patch_85.jpg\n",
      "  - F16_0172_patch_89.jpg\n",
      "  - F16_0172_patch_9.jpg\n",
      "  - F16_0172_patch_90.jpg\n",
      "  - F16_0172_patch_91.jpg\n",
      "  - F16_0172_patch_92.jpg\n",
      "  - F16_0172_patch_93.jpg\n",
      "  - F16_0172_patch_97.jpg\n",
      "  - F16_0172_patch_98.jpg\n",
      "  - F16_0172_patch_99.jpg\n",
      "\n",
      "Extra patches (in test folder, not in CSV): 2\n",
      "  - F21_0182_patch_4.jpg\n",
      "  - F2_0087_patch_2.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Inputs ===\n",
    "csv_path = r\"C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\metadata_with_brightness.csv\"\n",
    "test_dir = r\"C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\Raw_July\\Definitief_29_04\\Test_dataset\\test_v5_resize\" # This is the folder with subfolders per class\n",
    "\n",
    "# === Load CSV filenames ===\n",
    "df = pd.read_csv(csv_path)\n",
    "csv_filenames = set(df['patch_filename'].apply(lambda x: os.path.basename(x)))  # e.g., F2_0087_patch_37.jpg\n",
    "\n",
    "# === Extract and normalize filenames from test folder ===\n",
    "test_filenames = set()\n",
    "\n",
    "for root, _, files in os.walk(test_dir):\n",
    "    for f in files:\n",
    "        # Only process image files\n",
    "        if f.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Normalize filename by stripping Roboflow-style suffix\n",
    "            # Example: F9_0064_patch_126_jpg.rf.1ddde84dfb1f4b752e75c71f0158c010 → F9_0064_patch_126.jpg\n",
    "            match = re.match(r'^(.*?)(_jpg)?\\.rf\\..*\\.(jpg|jpeg|png)$', f)\n",
    "            if match:\n",
    "                base = match.group(1) + '.jpg'\n",
    "                test_filenames.add(base)\n",
    "            else:\n",
    "                # If no RF hash, still normalize to .jpg\n",
    "                test_filenames.add(os.path.splitext(f)[0] + '.jpg')\n",
    "\n",
    "# === Compare sets ===\n",
    "missing_patches = csv_filenames - test_filenames  # In CSV but not in folder\n",
    "extra_patches = test_filenames - csv_filenames    # In folder but not in CSV\n",
    "\n",
    "# === Output results ===\n",
    "print(f\"🔍 Missing patches (in CSV, not in test folder): {len(missing_patches)}\")\n",
    "for f in sorted(missing_patches):\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(f\"\\nExtra patches (in test folder, not in CSV): {len(extra_patches)}\")\n",
    "for f in sorted(extra_patches):\n",
    "    print(f\"  - {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4af6f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered CSV saved: 2198 patches retained out of 2330\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Inputs ===\n",
    "csv_path = r\"C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\metadata_with_brightness.csv\"\n",
    "test_dir = r\"C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\Raw_July\\Definitief_29_04\\Test_dataset\\test_v5_resize\" # This is the folder with subfolders per class\n",
    "\n",
    "# === Load CSV filenames ===\n",
    "df = pd.read_csv(csv_path)\n",
    "csv_filenames = set(df['patch_filename'].apply(lambda x: os.path.basename(x)))  # e.g., F2_0087_patch_37.jpg\n",
    "\n",
    "# === Get normalized test filenames from folder ===\n",
    "test_filenames = set()\n",
    "\n",
    "for root, _, files in os.walk(test_dir):\n",
    "    for f in files:\n",
    "        if f.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            match = re.match(r'^(.*?)(_jpg)?\\.rf\\..*\\.(jpg|jpeg|png)$', f)\n",
    "            if match:\n",
    "                normalized = match.group(1) + '.jpg'\n",
    "            else:\n",
    "                normalized = os.path.splitext(f)[0] + '.jpg'\n",
    "            test_filenames.add(normalized)\n",
    "\n",
    "# === Filter the CSV ===\n",
    "filtered_df = df[df['patch_filename'].isin(test_filenames)]\n",
    "\n",
    "# === Save result ===\n",
    "filtered_df.to_csv('filtered_test_brightness.csv', index=False)\n",
    "print(f\"✅ Filtered CSV saved: {len(filtered_df)} patches retained out of {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ab308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Two manual rows added.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load existing file\n",
    "df = pd.read_csv('filtered_test_brightness.csv')\n",
    "\n",
    "\n",
    "# Define your 2 manual rows\n",
    "manual_entries = pd.DataFrame([\n",
    "    {\n",
    "        'patch_filename': 'F2_0087_patch_2.jpg',\n",
    "        'segment': 'F2',\n",
    "        'photo_id': 87,\n",
    "        'patch_id': 2,\n",
    "        'x': 2816,\n",
    "        'y': 0,\n",
    "        'altitude': 35,\n",
    "        'true_label': 'Water-starwort',\n",
    "        'brightness': 22.432258,\n",
    "        'light_condition_new': 'shadow'\n",
    "    },\n",
    "    {\n",
    "        'patch_filename': 'F21_0182_patch_4.jpg',\n",
    "        'segment': 'F21',\n",
    "        'photo_id': 182,\n",
    "        'patch_id': 4,\n",
    "        'x': 1920,\n",
    "        'y': 0,\n",
    "        'altitude': 20,\n",
    "        'true_label': 'Clear water',\n",
    "        'brightness': 56.551120,\n",
    "        'light_condition_new': 'sun'\n",
    "    }\n",
    "])\n",
    "\n",
    "# Append and save\n",
    "df = pd.concat([df, manual_entries], ignore_index=True)\n",
    "df_sorted = df.sort_values(by=\"patch_filename\").reset_index(drop=True)\n",
    "df_sorted.to_csv('extended_test_brightness.csv', index=True)\n",
    "print(\"✅ Two manual rows added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03317ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric part of the segment for proper numerical sorting\n",
    "df_sorted[\"segment_num\"] = df_sorted[\"segment\"].str.extract(r'F(\\d+)').astype(int)\n",
    "\n",
    "# Sort by numeric segment, then photo_id, then patch_id\n",
    "df_sorted_numeric = df_sorted.sort_values(by=[\"segment_num\", \"photo_id\", \"patch_id\"]).drop(columns=\"segment_num\").reset_index(drop=True)\n",
    "\n",
    "df_sorted_numeric.to_csv('extend_test_brightness_sorted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b6e2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         patch_filename      true_label  brightness light_condition_new\n",
      "0  F21_0182_patch_4.jpg     Clear Water   56.551120                 sun\n",
      "1   F2_0087_patch_2.jpg  Water-starwort   22.432258              shadow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import re\n",
    "TEST_PATCH_DIR = r\"C:\\Users\\Sander\\OneDrive - UGent\\Semester_2\\Masterproef\\Thesis_ML\\Roboflow\\Raw_July\\Definitief_29_04\\Test_dataset\\test_v5_resize\"\n",
    "\n",
    "# === Thresholds per class ===\n",
    "brightness_thresholds = {\n",
    "    \"Clear Water\": 31,\n",
    "    \"Common reed\": 70,\n",
    "    \"Duckweed\": 92,\n",
    "    \"Other\": 56,\n",
    "    \"Water-starwort\": 61\n",
    "}\n",
    "\n",
    "\n",
    "# === Only calculate for these two patch names ===\n",
    "target_patches = {\"F2_0087_patch_2.jpg\", \"F21_0182_patch_4.jpg\"}\n",
    "\n",
    "# === Initialize output list ===\n",
    "brightness_records = []\n",
    "\n",
    "# === Loop through TEST_PATCH_DIR recursively ===\n",
    "for class_name in os.listdir(TEST_PATCH_DIR):\n",
    "    class_dir = os.path.join(TEST_PATCH_DIR, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        # Clean the Roboflow filename to match the target\n",
    "        match = re.match(r\"^(.*)_jpg\\.rf\\..*\\.jpg$\", img_file)\n",
    "        cleaned_name = match.group(1) + \".jpg\" if match else img_file\n",
    "\n",
    "        if cleaned_name in target_patches:\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            bright = np.array(img).mean()\n",
    "\n",
    "            threshold = brightness_thresholds.get(class_name, 100)\n",
    "            light_cond = \"shadow\" if bright < threshold else \"sun\"\n",
    "\n",
    "            brightness_records.append({\n",
    "                \"patch_filename\": cleaned_name,\n",
    "                \"true_label\": class_name,\n",
    "                \"brightness\": bright,\n",
    "                \"light_condition_new\": light_cond\n",
    "            })\n",
    "\n",
    "# === Convert to DataFrame and show results ===\n",
    "df_brightness = pd.DataFrame(brightness_records)\n",
    "print(df_brightness)\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df_brightness.to_csv(\"new_patch_brightness.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85606447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort first by segment (e.g., 'F2', 'F3', etc.) and then by patch_filename within each segment\n",
    "df_sorted_segment = df_combined.sort_values(by=[\"segment\", \"photo_id\", \"patch_id\"]).reset_index(drop=True)\n",
    "\n",
    "# Save the sorted CSV\n",
    "output_segment_path = \"/mnt/data/extended_test_brightness_sorted_by_segment.csv\"\n",
    "df_sorted_segment.to_csv(output_segment_path, index=False)\n",
    "\n",
    "# Display the first few rows to confirm sorting\n",
    "df_sorted_segment.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
